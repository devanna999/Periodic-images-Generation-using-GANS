{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2ae333d",
   "metadata": {},
   "source": [
    "# GANS are used to generate Periodic images \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9553854",
   "metadata": {},
   "source": [
    "# Imports for the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db533454",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "#%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.utils.data as data\n",
    "from torch import Tensor\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49561489",
   "metadata": {},
   "source": [
    "# Defining the hyperparameters for the neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc659751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory for dataset\n",
    "#dataroot = \"data/celeba\"\n",
    "\n",
    "# Number of workers for dataloader\n",
    "workers = 2\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 128\n",
    "# Spatial size of training images. All images will be resized to this\n",
    "#   size using a transformer.\n",
    "image_size = 64\n",
    "\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 1\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 100\n",
    "\n",
    "# Size of feature maps in generator\n",
    "ngf = 64\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 64\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs =100\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0002\n",
    "\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0.5\n",
    "\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add80ee5",
   "metadata": {},
   "source": [
    "# Defining  and loading the custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456116f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "from torch import Tensor\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "#import h5py\n",
    "\n",
    "\n",
    "\n",
    "def is_image_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in [\".hdf5\", \".h5\"])\n",
    "\n",
    "\n",
    "def load_img(filepath):\n",
    "    img = None\n",
    "    with h5py.File(filepath, \"r\") as f:\n",
    "        img = f['data'][()]\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    torch_img = Tensor(img)\n",
    "    torch_img = torch_img.div(255).sub(0.5).div(0.5)\n",
    "    return torch_img\n",
    "\n",
    "class HDF5Dataset(data.Dataset):\n",
    "    def __init__(self, image_dir, input_transform=None, target_transform=None):\n",
    "        super(HDF5Dataset, self).__init__()\n",
    "        self.image_filenames = [join(image_dir, x) for x in listdir(image_dir) if is_image_file(x)]\n",
    "        self.input_transform = input_transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input = load_img(self.image_filenames[index])\n",
    "        target = None\n",
    "\n",
    "        return input\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1276b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## normalize the data to have mean of zero and standard deviation 1\n",
    "transforms=transforms.Compose([\n",
    "                               transforms.Resize(64),\n",
    "                               transforms.CenterCrop(64),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5), (0.5)),\n",
    "                           ])\n",
    "dataset = HDF5Dataset(image_dir=\"training images\",input_transform=transforms)\n",
    "# dataset = HDF5Dataset(opt.dataroot,\n",
    "                          \n",
    "# comment mnist above and uncomment below if train on CelebA\n",
    "#dataset = datasets.ImageFolder(root=\"celeb_dataset\", transform=transforms)\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c993fddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BCELoss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Create batch of latent vectors that we will use to visualize\n",
    "#  the progression of the generator\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "# Establish convention for real and fake labels during training\n",
    "lab = get_truncated_normal(mean=0, sd=1, low=.7, upp=1.2)\n",
    "labf=lab.rvs()\n",
    "labs=get_truncated_normal(mean=0, sd=1, low=0, upp=0.3)\n",
    "labsf=labs.rvs()\n",
    "real_label = labf\n",
    "fake_label = labsf\n",
    "real_label=0.9 ## adding noise to stabilize the gan training\n",
    "fake_label=0.1\n",
    "\n",
    "# Setup Adam optimizers for both G and D\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12f309f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7826e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.conv1= nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0,bias=False)\n",
    "        self.b1=nn.BatchNorm2d(ngf * 8)\n",
    "        self.a1=nn.ReLU(True)\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "        self.conv2=nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2,padding=1, bias=False)\n",
    "        self.b2=nn.BatchNorm2d(ngf * 4)\n",
    "        self.a2=nn.ReLU(True)\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "        self.conv3=nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False)\n",
    "        self.b3=nn.BatchNorm2d(ngf * 2)\n",
    "        self.a3=nn.ReLU(True)\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "        self.conv4=nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False)\n",
    "        self.b4=nn.BatchNorm2d(ngf)\n",
    "        self.a4=nn.ReLU(True)\n",
    "            # state size. (ngf) x 32 x 32\n",
    "        self.conv5=nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False)\n",
    "        self.tanh=nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        \n",
    "\n",
    "    def forward(self, input):\n",
    "        print(input.size())\n",
    "        x=self.a1(self.b1(self.conv1(input)))\n",
    "        print(x.size())\n",
    "        \n",
    "        x=self.a2(self.b2(self.conv2(x)))\n",
    "        print(x.size())\n",
    "        x=F.pad(x,[1,1,1,1],mode='circular')\n",
    "        print('after padding size is {}'.format(x.size()))\n",
    "        x=self.a3(self.b3(self.conv3(x)))\n",
    "        print(x.size())\n",
    "        x=F.pad(x,[1,1,1,1],mode='circular')\n",
    "        print('after padding size is {}'.format(x.size()))\n",
    "        x=self.a4(self.b4(self.conv4(x)))\n",
    "        print(x.size())\n",
    "        \n",
    "        x=self.tanh(self.conv5(x))\n",
    "        print(x.size())\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1776f17a",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacebadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "\n",
    "# Lists to keep track of progress\n",
    "lr = 0.00002 ## training again with less learning rate \n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    # For each batch in the dataloader\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        \n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        ## Train with all-real batch\n",
    "        netD.zero_grad()\n",
    "        # Format batch\n",
    "        real_cpu = data.to(device)\n",
    "        b_size = real_cpu.size(0)\n",
    "        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
    "        # Forward pass real batch through D\n",
    "        output = netD(real_cpu).view(-1)\n",
    "        # Calculate loss on all-real batch\n",
    "        errD_real = criterion(output, label)\n",
    "        # Calculate gradients for D in backward pass\n",
    "        errD_real.backward()\n",
    "        #for p in list(filter(lambda p: p.grad is not None, netD.parameters())):\n",
    "           # print(p.grad.data.norm(2).item())\n",
    "        \n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate batch of latent vectors\n",
    "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        # Generate fake image batch with G\n",
    "        fake = netG(noise)\n",
    "        label.fill_(fake_label)\n",
    "        # Classify all fake batch with D\n",
    "        output = netD(fake.detach()).view(-1)\n",
    "        # Calculate D's loss on the all-fake batch\n",
    "        errD_fake = criterion(output, label)\n",
    "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "        \n",
    "        errD_fake.backward()\n",
    "        #for p in list(filter(lambda p: p.grad is not None, netD.parameters())):\n",
    "             #print(p.grad.data.norm(2).item())\n",
    "        D_G_z1 = output.mean().item()\n",
    "        # Compute error of D as sum over the fake and the real batches\n",
    "        errD = errD_real + errD_fake\n",
    "        # Update D\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "        output = netD(fake).view(-1)\n",
    "        # Calculate G's loss based on this output\n",
    "        errG = criterion(output, label)\n",
    "        # Calculate gradients for G\n",
    "        errG.backward()\n",
    "        #for p in list(filter(lambda p: p.grad is not None, netG.parameters())):\n",
    "                # print(p.grad.data.norm(2).item())\n",
    "        D_G_z2 = output.mean().item()\n",
    "        # Update G\n",
    "        optimizerG.step()\n",
    "        \n",
    "        # Output training stats\n",
    "        if i % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                  % (epoch, num_epochs, i, len(dataloader),\n",
    "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "        \n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "        \n",
    "        # Check how the generator is doing by saving G's output on fixed_noise\n",
    "        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = netG(fixed_noise).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "            \n",
    "        iters += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419a0409",
   "metadata": {},
   "source": [
    "## loading the required image processing Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043d9bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import h5py\n",
    "import tifffile\n",
    "from scipy.ndimage.filters import median_filter\n",
    "from skimage.filters import threshold_otsu\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bfbb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modell = Generator(1)\n",
    "modell.load_state_dict(torch.load('model_weights3.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f225db",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_test = torch.randn(128, nz, 1, 1)\n",
    "test1=modell(noise_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d62bf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96113e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import h5py\n",
    "import tifffile\n",
    "from scipy.ndimage.filters import median_filter\n",
    "from skimage.filters import threshold_otsu\n",
    "from collections import Counter\n",
    "b_size=128\n",
    "generated_images=[]\n",
    "for index in range(5):\n",
    "    noise_test = torch.randn(b_size, nz, 1, 1)\n",
    "    test1=modell(noise_test)\n",
    "    test1_final=test1[0].reshape(88,88).cpu().detach().numpy()\n",
    "    generated_images.append(test1_final)\n",
    "\n",
    "figure=plt.figure(figsize=(15,7))\n",
    "for index,image in enumerate(generated_images):\n",
    "    plt.subplot(1,5,index+1)\n",
    "    plt.title('synthetic_image'+str(index))\n",
    "    plt.axis('off')\n",
    "\n",
    "\n",
    "    test1_final = median_filter(image,size=(3,3))\n",
    "    #test1_final = median_filter(test1_final,size=(22))\n",
    "\n",
    "    threshold_global_otsu = threshold_otsu(test1_final)\n",
    "\n",
    "    segmented_image = (test1_final >= threshold_global_otsu).astype(np.int32)\n",
    "\n",
    "    plt.imshow(segmented_image,cmap='Greys')\n",
    " \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2f37d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
